{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This algorithm could be useful for feature selection because we optimize each theta[i]\n",
    "# seperately, and therefore can watch how performance improves when we add the optimized \n",
    "# theta[i] to theta versus the predictability of thetaBar.\n",
    "\n",
    "# In addition, this algorithm tends to produce thetas with a good deal of zeros, so we can\n",
    "# filter out any feature i such that theta[i] = 0\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def L1LeastSquaresLinReg(Xtrain, ytrain, Xtest):\n",
    "    lmbda = 1000\n",
    "    theta = L1LeastSquares(Xtrain, ytrain, lmbda)\n",
    "    return Xtest.dot(theta)\n",
    "        \n",
    "    \n",
    "def L1LeastSquares(X, y, lmbda):\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    stop = 0\n",
    "    it = 100\n",
    "    while (not stop) and (it > 0):\n",
    "        stop = 1\n",
    "        for i in range(X.shape[1]):\n",
    "            ti = theta[i]\n",
    "            thetaBar = theta[:]\n",
    "            thetaBar[i] = 0\n",
    "            s = 1 if ti >= 0 else -1\n",
    "            #Perform update\n",
    "            Xi = X[:, i]\n",
    "            XiT = Xi.transpose()\n",
    "            theta[i] = (XiT.dot(y - X.dot(thetaBar)) + s*lmbda)/(XiT.dot(Xi))\n",
    "            #Clip theta's value\n",
    "            theta[i] = max(theta[i], 0) if s == 1 else min(theta[i], 0)\n",
    "            if abs(ti - theta[i]) > 10**-5:\n",
    "                stop = 0\n",
    "        it = it - 1\n",
    "    print theta\n",
    "    return theta\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.16058258e-01   0.00000000e+00   4.61689682e+01   1.16278057e-01\n",
      "   2.34955020e-01   5.34273113e-01   3.79262176e-01   6.16124339e+01\n",
      "   4.79026364e-01   9.99116677e+01   3.07816442e-01   1.68770369e-01\n",
      "   2.99164488e-01   6.16103303e+01   3.66459026e-01   0.00000000e+00\n",
      "   9.66409296e+01   3.97099404e-02   8.14831638e+01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.76974651e-01   2.38065618e-01\n",
      "   2.66696360e-01   3.25256470e-01   3.73899350e-01   1.89356961e-01\n",
      "   9.97205758e+00   0.00000000e+00   3.92875685e+01   0.00000000e+00\n",
      "   7.80197603e-03   0.00000000e+00   5.86146050e-01   1.03746556e-02\n",
      "   2.98848970e-01   4.56426106e+01   0.00000000e+00   3.54739670e+01\n",
      "   0.00000000e+00   7.58442603e-02   1.63796656e-01   0.00000000e+00\n",
      "   3.55436704e-01   8.96753973e+01   0.00000000e+00   0.00000000e+00\n",
      "   3.92118368e-01   5.74128863e-03   0.00000000e+00   1.45684534e-01\n",
      "   1.53579106e-01   4.97868059e+01   3.53422843e-01   8.53058869e+01\n",
      "   5.16997359e-01   0.00000000e+00   0.00000000e+00   2.39565319e-01\n",
      "   6.23897243e+01   4.50200608e-01   2.16825068e-01   5.12229894e+01\n",
      "   9.79499447e+01   6.19940464e-02   4.93591687e-01   2.25077544e-01\n",
      "   0.00000000e+00   0.00000000e+00   2.35330900e+01   6.36719947e-01\n",
      "   2.44184830e-01   2.10250522e-01   1.62105442e-01   1.34481886e-01\n",
      "   6.13950171e-01   3.66106156e-02   9.50995708e+01   3.16893548e-01\n",
      "   1.53873815e-01   3.75895453e-01   1.56412535e-02   8.19073707e+01\n",
      "   4.86784917e-01   2.23417603e-01   0.00000000e+00   5.80405231e-01\n",
      "   0.00000000e+00   1.04716615e-01   1.57040380e-01   2.73279147e-01\n",
      "   3.35602811e-02   3.29807038e-02   5.41269741e-02   7.41846992e-02\n",
      "   1.47867008e-01   6.42534516e+01   0.00000000e+00   3.67013052e-01]\n",
      "0.995462826087\n",
      "0.995454860103\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n",
    "from numpy.random import permutation\n",
    "from sklearn.metrics import r2_score\n",
    "n_samples = 10000\n",
    "\n",
    "\n",
    "X,y,coeff = datasets.make_regression(n_samples=n_samples, n_features=100,\n",
    "                                      n_informative=20, noise=20,\n",
    "                                      coef=True, random_state=0)\n",
    "# indices = permutation(range(150))\n",
    "# X = X[indices]\n",
    "# y = y[indices]\n",
    "\n",
    "Xtrain = X[:-1000]\n",
    "ytrain = y[:-1000]\n",
    "Xtest =  X[-1000:]\n",
    "ytest =  y[-1000:]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(Xtrain, ytrain)\n",
    "\n",
    "predictionsSK = model.predict(Xtest)\n",
    "predictionsME = L1LeastSquaresLinReg(Xtrain, ytrain, Xtest)\n",
    "\n",
    "\n",
    "print r2_score(predictionsSK, ytest)\n",
    "print r2_score(predictionsME, ytest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
